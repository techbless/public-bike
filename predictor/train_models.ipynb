{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade pip\n",
    "# !pip install python-dotenv\n",
    "# !pip install numpy\n",
    "# !pip install pandas\n",
    "# !pip install tensorflow\n",
    "# !pip install keras\n",
    "# !pip install matplotlib\n",
    "# !pip install sklearn\n",
    "# !pip install PyMySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "s0U--D6UWZPS",
    "outputId": "4ed23761-1e59-429d-8bdf-f62ec7b8ad3a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import pymysql\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, TimeDistributed, RepeatVector\n",
    "\n",
    "tf.config.threading.set_intra_op_parallelism_threads(2)\n",
    "tf.config.threading.set_inter_op_parallelism_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DB_CONN INFOS\n",
    "DB_USER = os.getenv('MYSQL_USER')\n",
    "DB_PASSWD = os.getenv('MYSQL_PASSWORD')\n",
    "DB_HOST = os.getenv('MYSQL_HOST')\n",
    "DB_DB = os.getenv('MYSQL_DATABASE')\n",
    "\n",
    "# Connect to db\n",
    "db = pymysql.connect(\n",
    "    user=DB_USER, \n",
    "    passwd=DB_PASSWD, \n",
    "    host=DB_HOST, \n",
    "    db=DB_DB, \n",
    "    charset='utf8'\n",
    ")\n",
    "\n",
    "# Set cursor\n",
    "cursor = db.cursor(pymysql.cursors.DictCursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get all stations ids in database\n",
    "sql = \"SELECT TABLE_NAME FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_SCHEMA = %s;\"\n",
    "nRows = cursor.execute(sql, DB_DB)\n",
    "stationIds = cursor.fetchall()\n",
    "stationIds = [stationId['TABLE_NAME'] for stationId in stationIds]\n",
    "stationIds = stationIds[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로딩시간 : 0.6876561641693115\n",
      "로드된 데이터 수 : 61140\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "count = 0\n",
    "data = {}\n",
    "for stationId in stationIds:\n",
    "    sql = \"SELECT parkingBikeTotCnt FROM `{}`\".format(stationId)\n",
    "    count += cursor.execute(sql)\n",
    "    res = cursor.fetchall()\n",
    "    \n",
    "    tempdf = pd.DataFrame(res)\n",
    "    y = pd.DataFrame(tempdf.parkingBikeTotCnt)\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    y = scaler.fit_transform(y)\n",
    "    \n",
    "    # filter only dataset which have more than 1k data\n",
    "    # IMPORTANT: This is very important to ensure safe training.\n",
    "    #            because some stations' dataset has very small data.\n",
    "    if(len(y) > 1000):\n",
    "        data[stationId] = y\n",
    "    \n",
    "print(\"로딩시간 :\", time.time() - start)\n",
    "print(\"로드된 데이터 수 :\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mYDVkTUVWosT"
   },
   "outputs": [],
   "source": [
    "def create_dataset(dataset, look_back=10, nPredicted = 6):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-nPredicted + 1):\n",
    "        dataX.append(dataset[i:(i+look_back), 0])\n",
    "        dataY.append(dataset[i + look_back: i + look_back + nPredicted, 0])\n",
    "        \n",
    "    dataX, dataY = np.array(dataX), np.array(dataY)\n",
    "    \n",
    "    dataX = dataX.reshape(dataX.shape[0], dataX.shape[1], 1)\n",
    "    dataY = dataY.reshape(dataY.shape[0], dataY.shape[1], 1)\n",
    "    \n",
    "    return dataX, dataY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_all_task(args):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(25, activation='linear', input_shape=(10, 1)))\n",
    "    model.add(RepeatVector(6))\n",
    "    model.add(LSTM(25, activation='linear', return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(1)))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    if debug:\n",
    "        start = time.time()\n",
    "        history = model.fit(args['x'], args['y'], epochs=250, batch_size=70, verbose=0)\n",
    "        print(\"[{:^9}] {:>5}초, loss: {}\".format(args['key'], round(time.time() - start, 2), round(history.history['loss'][-1:][0], 4)))\n",
    "    else:\n",
    "        model.fit(args['x'], args['y'], epochs=200, batch_size=64, verbose=0)\n",
    "          \n",
    "    file_name = 'models/{}.h5'.format(args['key'])\n",
    "    model.save(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joining pool processes\n",
      "Join complete\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    nCores = multiprocessing.cpu_count()\n",
    "    pool = multiprocessing.Pool(processes=nCores)\n",
    "\n",
    "    keys = data.keys()\n",
    "    result = pool.map(create_dataset, [data[key] for key in keys])\n",
    "\n",
    "    datasets = {}\n",
    "    idx = 0\n",
    "    for key in keys:\n",
    "        datasets[key] = result[idx]\n",
    "        idx+=1\n",
    "except:\n",
    "    pool.terminate()\n",
    "    print('Pool is terminated')\n",
    "finally:\n",
    "    print('Joining pool processes')\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    print('Join complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== 학습 시작 ==\n",
      "[ ST-1006 ] 40.41초, loss: 0.0057\n",
      "[ ST-1002 ] 40.62초, loss: 0.0029\n",
      "[  ST-10  ] 40.67초, loss: 0.0055\n",
      "[ ST-1004 ]  40.8초, loss: 0.003\n",
      "[ ST-1007 ] 40.44초, loss: 0.0034\n",
      "[ ST-1000 ] 40.35초, loss: 0.0019\n",
      "[ ST-1003 ] 40.58초, loss: 0.0029\n",
      "[ ST-1005 ] 40.42초, loss: 0.0021\n",
      "[ ST-1011 ] 40.69초, loss: 0.0015\n",
      "[ ST-1008 ] 41.06초, loss: 0.0027\n",
      "[ ST-1015 ] 40.77초, loss: 0.0035\n",
      "[ ST-1013 ] 40.85초, loss: 0.0082\n",
      "[ ST-1012 ] 40.51초, loss: 0.0022\n",
      "[ ST-1010 ] 40.58초, loss: 0.0019\n",
      "[ ST-1016 ] 40.77초, loss: 0.0025\n",
      "[ ST-1014 ] 40.72초, loss: 0.0036\n",
      "[ ST-1017 ]  41.2초, loss: 0.0056\n",
      "[ ST-1024 ] 40.92초, loss: 0.0028\n",
      "[ ST-1019 ] 41.23초, loss: 0.0034\n",
      "[ ST-1020 ] 41.23초, loss: 0.0024\n",
      "[ ST-1018 ] 40.92초, loss: 0.0088\n",
      "[ ST-102  ] 40.67초, loss: 0.0115\n",
      "[ ST-1025 ] 41.07초, loss: 0.002\n",
      "[ ST-1023 ] 40.86초, loss: 0.0007\n",
      "[ ST-1029 ] 39.98초, loss: 0.0048\n",
      "[ ST-1027 ] 40.09초, loss: 0.0023\n",
      "[ ST-1031 ]  40.6초, loss: 0.0091\n",
      "[ ST-103  ] 39.78초, loss: 0.003\n",
      "[ ST-1028 ] 40.14초, loss: 0.0027\n",
      "[ ST-1032 ] 39.72초, loss: 0.0046\n",
      "\n",
      "\n",
      "== 학습 완료 == \n",
      "소요 시간 : 326.39\n",
      "joining pool processes\n",
      "join complete\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    start = time.time()\n",
    "    print(\"== 학습 시작 ==\")\n",
    "    #print(\"*\" * len(datasets))\n",
    "\n",
    "    nCores = multiprocessing.cpu_count()\n",
    "    pool = multiprocessing.Pool(processes=4)\n",
    "\n",
    "    keys = datasets.keys()\n",
    "    res = pool.map(do_all_task, [{\n",
    "        'key': key, \n",
    "        'x': datasets[key][0], \n",
    "        'y': datasets[key][1]\n",
    "    } for key in keys])\n",
    "\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"== 학습 완료 == \")\n",
    "    print(\"소요 시간 :\", round(time.time() - start, 2))\n",
    "except:\n",
    "    print('에러가 발생 했습니다')\n",
    "    pool.terminate()\n",
    "    print('pool is terminated')\n",
    "finally:\n",
    "    print('joining pool processes')\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    print('join complete')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Untitled5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
